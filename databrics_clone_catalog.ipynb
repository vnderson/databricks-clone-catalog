{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from delta.tables import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.errors import PySparkException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Parameters ##\n",
    "dbutils.widgets.text('catalog_source', '')\n",
    "catalog_source = dbutils.widgets.get('catalog_source')\n",
    "################\n",
    "dbutils.widgets.text('catalog_target', '')\n",
    "catalog_target = dbutils.widgets.get('catalog_target')\n",
    "################\n",
    "dbutils.widgets.text('full_catalog', '')\n",
    "full_catalog = dbutils.widgets.get('full_catalog')\n",
    "################\n",
    "dbutils.widgets.text('schemas_clone', '')\n",
    "schemas_clone = dbutils.widgets.get('schemas_clone')\n",
    "################\n",
    "dbutils.widgets.text('tables_clone', '')\n",
    "tables_clone = dbutils.widgets.get('tables_clone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schemas_clone = [s for s in schemas_clone.split(',') if s != '']\n",
    "tables_clone = [t for t in tables_clone.split(',') if t != '']\n",
    "CLONE_TYPE = 'deep'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_schemas_from_catalog(catalog_source):\n",
    "    try: \n",
    "        df_schemas = spark.sql(f'SHOW SCHEMAS IN {catalog_source}')\n",
    "        lst_schemas = [s[0] for s in df_schemas.select('databaseName').collect()]\n",
    "    except:\n",
    "        print(f'Catalog {catalog_source} does not exist.')\n",
    "        lst_schemas = []\n",
    "    return lst_schemas\n",
    "\n",
    "def get_tables_from_schema(catalog_source, schema_name):\n",
    "    try: \n",
    "        df_tables = spark.sql(f'SHOW TABLES IN {catalog_source}.{schema_name}')\n",
    "        lst_tables = [t[0] for t in df_tables.select('tableName').collect()]\n",
    "    except:\n",
    "        print(f'Schema {schema_name} does not exist in {catalog_source}.')\n",
    "        lst_tables = []\n",
    "    return lst_tables\n",
    "\n",
    "def get_container_from_catalog(catalog_target):\n",
    "    try:\n",
    "        df = spark.sql(f'DESCRIBE CATALOG EXTENDED {catalog_target}')\n",
    "        storage_location = df.filter(col('info_name') == 'Storage Root').collect()[0][1]\n",
    "        container_target = storage_location.replace('abfss://', '')\n",
    "    except PySparkException as ex:\n",
    "        if (ex.getErrorClass() == \"NO_SUCH_CATALOG_EXCEPTION\"):\n",
    "            container_target = f'Catalog {catalog_target} does not exist.'\n",
    "        else:\n",
    "            raise\n",
    "    return container_target\n",
    "\n",
    "def clone_table(catalog_source, catalog_target, schema_name, table_name, clone_type):\n",
    "    container_target = get_container_from_catalog(catalog_target)\n",
    "    if not(container_target.endswith(' does not exist.')):\n",
    "        location = f'abfss://{container_target}{schema_name}/{table_name}'\n",
    "        print(f'Cloning table {catalog_source}.{schema_name}.{table_name} to {catalog_target}...')\n",
    "        if clone_type.upper() in ['SHALLOW', 'DEEP']:\n",
    "            try:\n",
    "                spark.sql(f\"\"\"\n",
    "                    CREATE OR REPLACE TABLE {catalog_target}.{schema_name}.{table_name} \n",
    "                    {clone_type} CLONE {catalog_source}.{schema_name}.{table_name} \n",
    "                    LOCATION '{location}'\n",
    "                \"\"\")\n",
    "            except PySparkException as ex:\n",
    "                if (ex.getErrorClass() == \"TABLE_OR_VIEW_NOT_FOUND\"):\n",
    "                    print(f'Table {catalog_source}.{schema_name}.{table_name} does not exist.')\n",
    "                else:\n",
    "                    raise\n",
    "        else:\n",
    "            print('Invalid Clone Type. Valid clone types are \"shallow\" or \"deep\".')\n",
    "    else:\n",
    "        print(container_target)\n",
    "\n",
    "def create_schema(catalog_source, catalog_target, schema_name):\n",
    "    df_schemas = spark.sql(f'SHOW SCHEMAS IN {catalog_source}')\n",
    "    lst_schemas = [t[0] for t in df_schemas.select('databaseName').collect() if t[0] == schema_name]\n",
    "    if len(lst_schemas)>0:\n",
    "        print(f'Creating schema {schema_name} on catalog {catalog_target}')\n",
    "        spark.sql(f'CREATE SCHEMA IF NOT EXISTS {catalog_target}.{schema_name}')\n",
    "    else:\n",
    "        print(f'Schema {schema_name} does not exist in {catalog_source}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if full_catalog == 'Y': \n",
    "    # Copy Full Catalog\n",
    "    for schema_name in get_schemas_from_catalog(catalog_source):\n",
    "        create_schema(catalog_source, catalog_target, schema_name)\n",
    "        for table_name in get_tables_from_schema(catalog_source, schema_name):\n",
    "            clone_table(catalog_source, catalog_target, schema_name, table_name, CLONE_TYPE)\n",
    "else:\n",
    "    # Copy Only Specified Tables\n",
    "    if (len(schemas_clone) == 0 and len(tables_clone) > 0):\n",
    "        for schema_table in tables_clone:\n",
    "            schema_name, table_name =  schema_table.split('.')[0], schema_table.split('.')[1]\n",
    "            create_schema(catalog_source, catalog_target, schema_name)            \n",
    "            clone_table(catalog_source, catalog_target, schema_name, table_name, CLONE_TYPE)\n",
    "    # Copy Only Specified Schemas\n",
    "    elif (len(schemas_clone) > 0 and len(tables_clone) == 0):\n",
    "        for schema_name in schemas_clone:\n",
    "            create_schema(catalog_source, catalog_target, schema_name)\n",
    "            for table_name in get_tables_from_schema(catalog_source, schema_name):\n",
    "                clone_table(catalog_source, catalog_target, schema_name, table_name, CLONE_TYPE)\n",
    "    else:\n",
    "        print('Please provide correct parameters to a full copy of the catalog, a list of schemas, or a list of tables!')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
